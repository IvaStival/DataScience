{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvaStival/DataScience/blob/master/RCNN/code/RCNN_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Bu8JDOS_nq",
        "outputId": "092a5b8e-24c8-44ca-fc20-d27e35d3ef24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VqmfZ5RTACs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aefHrv3TiCk"
      },
      "outputs": [],
      "source": [
        "def unzipFolders(file_path, destiny):\n",
        "  with zipfile.ZipFile(file_path, \"r\") as z:\n",
        "    z.extractall(destiny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqVSahDrTP7q"
      },
      "outputs": [],
      "source": [
        "def showImages(img_path, csv_path, filename):\n",
        "    csv_filename = filename.split('.')[0] + \".csv\"\n",
        "\n",
        "    image = cv2.imread(os.path.join(img_path, filename))\n",
        "    df = pd.read_csv(os.path.join(csv_path, csv_filename))\n",
        "\n",
        "    gtvalues = []\n",
        "    plt.imshow(image)\n",
        "    for row in df.iterrows():\n",
        "        x1 = int(row[1][0].split(\" \")[0])\n",
        "        y1 = int(row[1][0].split(\" \")[1])\n",
        "        x2 = int(row[1][0].split(\" \")[2])\n",
        "        y2 = int(row[1][0].split(\" \")[3])\n",
        "        gtvalues.append({\"x1\":x1, \"x2\":x2, \"y1\":y1, \"y2\":y2})\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7G4ShlTVNU"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/DataScience/RCNN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS0-WLDqT6rt"
      },
      "outputs": [],
      "source": [
        "image_zip = f\"{path}/dataset/Images.zip\"\n",
        "csv_zip = f\"{path}/dataset/Airplanes_Annotations.zip\"\n",
        "destiny = f\"{path}/dataset\"\n",
        "\n",
        "# unzipFolders(image_zip, destiny)\n",
        "# unzipFolders(csv_zip, destiny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah5tGFq4T40y"
      },
      "outputs": [],
      "source": [
        "showImages(f\"{path}/dataset/Images\", f\"{path}/dataset/Airplanes_Annotations\", \"airplane_001.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej3tuWryVRsV"
      },
      "outputs": [],
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1[\"x1\"] < bb1[\"x2\"]\n",
        "    assert bb1[\"y1\"] < bb1[\"y2\"]\n",
        "    assert bb2[\"x1\"] < bb2[\"x2\"]\n",
        "    assert bb2[\"y1\"] < bb2[\"y2\"]\n",
        "\n",
        "    x_left   = max(bb1[\"x1\"], bb2[\"x1\"])\n",
        "    y_top    = max(bb1[\"y1\"], bb2[\"y1\"])\n",
        "    x_right  = min(bb1[\"x2\"], bb2[\"x2\"])\n",
        "    y_bottom = min(bb1[\"y2\"], bb2[\"y2\"])\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    interseption_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    bb1_area = (bb1[\"x2\"] - bb1[\"x1\"]) * (bb1[\"y2\"] - bb1[\"y1\"])\n",
        "    bb2_area = (bb2[\"x2\"] - bb2[\"x1\"]) * (bb2[\"y2\"] - bb2[\"y1\"])\n",
        "\n",
        "    iou = interseption_area / float(bb1_area + bb2_area - interseption_area)\n",
        "\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    \n",
        "    return iou\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEXi_n3y5A5U"
      },
      "outputs": [],
      "source": [
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "def imageRecognition(path, csv_path, filename, e):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    csv_filename = filename.split('.')[0] + \".csv\"\n",
        "#     print(f\"{e} {filename}\")\n",
        "\n",
        "    image = cv2.imread(os.path.join(path, filename))\n",
        "    df = pd.read_csv(os.path.join(csv_path, csv_filename))\n",
        "\n",
        "    gtvalues = []\n",
        "\n",
        "    for row in df.iterrows():\n",
        "        x1 = int(row[1][0].split(\" \")[0])\n",
        "        y1 = int(row[1][0].split(\" \")[1])\n",
        "        x2 = int(row[1][0].split(\" \")[2])\n",
        "        y2 = int(row[1][0].split(\" \")[3])\n",
        "        gtvalues.append({\"x1\":x1, \"x2\":x2, \"y1\":y1, \"y2\":y2})\n",
        "\n",
        "    ss.setBaseImage(image)\n",
        "    ss.switchToSelectiveSearchFast()\n",
        "    ssresults = ss.process()\n",
        "    imout = image.copy()\n",
        "\n",
        "    counter = 0\n",
        "    false_counter = 0\n",
        "    flag = 0\n",
        "    fflag = 0\n",
        "    bflag = 0\n",
        "\n",
        "    for e, result in enumerate(ssresults):\n",
        "        if e < 2000 and flag == 0:\n",
        "            for gtval in gtvalues:\n",
        "                x, y, w, h = result\n",
        "\n",
        "                iou = get_iou(gtval, {\"x1\":x, \"x2\":x+w, \"y1\":y, \"y2\":y+h})\n",
        "\n",
        "                if counter < 30:\n",
        "                    if iou > 0.70:\n",
        "                        timage = imout[y:y+h, x:x+w]\n",
        "                        resized = cv2.resize(timage, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "                        train_images.append(resized)\n",
        "                        train_labels.append(1)\n",
        "                        counter += 1\n",
        "                else:\n",
        "                    fflag = 1\n",
        "                if false_counter < 30:\n",
        "                    if iou < 0.3:\n",
        "                        timage = imout[y:y+h, x:x+w]\n",
        "                        resized = cv2.resize(timage, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "                        train_images.append(resized)\n",
        "                        train_labels.append(0)\n",
        "                        false_counter += 1\n",
        "                else:\n",
        "                    bflag = 1\n",
        "            if fflag == 1 and bflag == 1:\n",
        "                print(\"inside\")\n",
        "                flag = 1\n",
        "                \n",
        "    return (train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrDA2wtx5HjG"
      },
      "outputs": [],
      "source": [
        "class MyLabelBinarizer(LabelBinarizer):\n",
        "    def transform(self, y):\n",
        "        Y = super().transform(y)\n",
        "        if self.y_type_ == \"binary\":\n",
        "            return np.hstack((Y, 1-Y))\n",
        "        else:\n",
        "            return Y\n",
        "        \n",
        "    def inverse_transform(self, Y, threshold=None):\n",
        "        if self.y_type_ == \"binary\":\n",
        "            return super().inverse_transform(Y[:, 0], threshold)\n",
        "        else:\n",
        "            return super().inverse_transform(Y, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3XPg2bV5Kjq"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "    path = \"/content/drive/MyDrive/DataScience/RCNN/dataset/Images\"\n",
        "    csv_path = \"/content/drive/MyDrive/DataScience/RCNN/dataset/Airplanes_Annotations\"\n",
        "    \n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    \n",
        "    train_images, train_labels = imageRecognition(path, csv_path, \"airplane_001.jpg\", 1)\n",
        "#     for i in train_images:\n",
        "#         plt.imshow(i)\n",
        "#         plt.show()\n",
        "#     for e, i in enumerate(os.listdir(path)):\n",
        "#         try:\n",
        "#             if i.startswith(\"airplane\"):\n",
        "#                 tem_images, temp_labels = imageRecognition(path, csv_path, i, e)\n",
        "#                 train_images += temp_images\n",
        "#                 train_labels += temp_labels\n",
        "#         except Exception as e:\n",
        "#             print(e)\n",
        "#             print(\"Error\")\n",
        "#             continue\n",
        "\n",
        "    X_new = np.array(train_images)\n",
        "    Y_new = np.array(train_labels)\n",
        "\n",
        "    vggmodel = VGG16(weights=\"imagenet\", include_top = True)\n",
        "\n",
        "    for layers in (vggmodel.layers)[:15]:\n",
        "        layers.trainable = False\n",
        "\n",
        "    X = vggmodel.layers[-2].output\n",
        "    predictions = Dense(2, activation = \"softmax\")(X)\n",
        "    model_final = Model(vggmodel.input, predictions)\n",
        "    opt = Adam(learning_rate = 0.001)\n",
        "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
        "    model_final.summary()\n",
        "    \n",
        "    lenc = MyLabelBinarizer()\n",
        "    Y = lenc.fit_transform(Y_new)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size=0.1)\n",
        "\n",
        "    print(len(X_train / 40))\n",
        "    \n",
        "    trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "    traindata = trdata.flow(x=X_train, y=Y_train, batch_size=10)\n",
        "    \n",
        "    tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "    testdata = tsdata.flow(x=X_test, y=Y_test, batch_size=2)\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(\"../models/ieeecnn_vgg16_1.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", period=1)\n",
        "    \n",
        "    early = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=100, verbose=1, mode=\"auto\")\n",
        "    \n",
        "    hist = model_final.fit(traindata, steps_per_epoch=15, epochs=10, validation_data=testdata, validation_steps=2, callbacks=[checkpoint, early])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9XnRU_35TGg",
        "outputId": "4728dc6a-0fe7-42f3-99e7-bd3abdf300bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inside\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 126,633,474\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "54\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 575.4094 - accuracy: 0.5000\n",
            "Epoch 00001: val_loss improved from inf to 1.79212, saving model to ../models/ieeecnn_vgg16_1.h5\n",
            "15/15 [==============================] - 32s 606ms/step - loss: 575.4094 - accuracy: 0.5000 - val_loss: 1.7921 - val_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.2445 - accuracy: 0.5333\n",
            "Epoch 00002: val_loss improved from 1.79212 to 1.02224, saving model to ../models/ieeecnn_vgg16_1.h5\n",
            "15/15 [==============================] - 35s 3s/step - loss: 5.2445 - accuracy: 0.5333 - val_loss: 1.0222 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8041 - accuracy: 0.5667\n",
            "Epoch 00003: val_loss did not improve from 1.02224\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.8041 - accuracy: 0.5667 - val_loss: 1.4684 - val_accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9916 - accuracy: 0.4333\n",
            "Epoch 00004: val_loss improved from 1.02224 to 0.74669, saving model to ../models/ieeecnn_vgg16_1.h5\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.9916 - accuracy: 0.4333 - val_loss: 0.7467 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.5000\n",
            "Epoch 00005: val_loss did not improve from 0.74669\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.7486 - accuracy: 0.5000 - val_loss: 0.7940 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.3333\n",
            "Epoch 00006: val_loss did not improve from 0.74669\n",
            "15/15 [==============================] - 2s 121ms/step - loss: 0.7952 - accuracy: 0.3333 - val_loss: 0.9322 - val_accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.4667\n",
            "Epoch 00007: val_loss improved from 0.74669 to 0.58249, saving model to ../models/ieeecnn_vgg16_1.h5\n",
            "15/15 [==============================] - 18s 1s/step - loss: 0.8321 - accuracy: 0.4667 - val_loss: 0.5825 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7419 - accuracy: 0.5000\n",
            "Epoch 00008: val_loss did not improve from 0.58249\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.7419 - accuracy: 0.5000 - val_loss: 0.6714 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.5333\n",
            "Epoch 00009: val_loss did not improve from 0.58249\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 0.6910 - accuracy: 0.5333 - val_loss: 0.7285 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7410 - accuracy: 0.6000\n",
            "Epoch 00010: val_loss did not improve from 0.58249\n",
            "15/15 [==============================] - 2s 121ms/step - loss: 0.7410 - accuracy: 0.6000 - val_loss: 0.6719 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9dWX2RY5Tw9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RCNN_Colab.ipynb",
      "provenance": [],
      "mount_file_id": "1g1sBnAE0rF-ZyhQERk-_PUhOVYxsZvB6",
      "authorship_tag": "ABX9TyPMjnjoYoSbVIeF4wrtqpk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}