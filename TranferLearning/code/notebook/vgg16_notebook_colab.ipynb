{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "import tensorflow.keras, os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "path = os.getcwd().split(\"code\")[0]\n",
        "dataset_name = \"dogs-vs-cats\"\n",
        "unzip = False\n",
        "\n",
        "def unzipDataSet(zipfile_name, directory):\n",
        "    with zipfile.ZipFile(f\"{path}/dataset/{dataset_name}/{zipfile_name}\", \"r\") as z:\n",
        "        z.extractall(f\"{path}/dataset/images/{directory}\")\n",
        "\n",
        "def createDataFrameFromDirectory(directory):\n",
        "    list_of_files = [os.path.join(f\"{path}/dataset/images/{directory}\", file) for file in os.listdir(f\"{path}/dataset/images/{directory}\")]\n",
        "\n",
        "    df = pd.DataFrame({\"Path\" : list_of_files})\n",
        "    df[\"animal\"] = np.where(df[\"Path\"].str.contains(\"dog\"), \"dog\", \"cat\")\n",
        "\n",
        "    return df\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "def setModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(input_shape = (64,64, 3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "def run():\n",
        "    if unzip:\n",
        "        unzipDataSet(\"train.zip\", \"train\")\n",
        "        unzipDataSet(\"test1.zip\", \"test\")\n",
        "\n",
        "    df_train = createDataFrameFromDirectory(\"train/train\")\n",
        "    df_test = createDataFrameFromDirectory(\"test/test1\")\n",
        "\n",
        "    X_Train, X_Test = train_test_split(df_train, test_size=0.3)\n",
        "\n",
        "    print(X_Train.shape)\n",
        "\n",
        "    tr_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                    shear_range = 0.2,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "    ts_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "    train_set = tr_datagen.flow_from_dataframe(dataframe=X_Train, x_col=\"Path\", y_col=\"animal\", class_mode=\"categorical\", target_size=(64,64), batch_size=128)\n",
        "    test_set  = ts_datagen.flow_from_dataframe(dataframe=X_Test,  x_col=\"Path\", y_col=\"animal\", class_mode=\"categorical\", target_size=(64,64), batch_size=128)\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model = setModel()\n",
        "\n",
        "    model.compile(optimizer = opt, loss=categorical_crossentropy, metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    checkpoint = ModelCheckpoint(f\"{path}/models/vgg16_1.h5\", monitor=\"accuracy\", verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", save_freq=1)\n",
        "    early = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=20, verbose=1, mode=\"auto\")\n",
        "\n",
        "    hist = model.fit_generator(steps_per_epoch=1, generator=train_set, validation_data=test_set, validation_steps=10, epochs=1, callbacks=[checkpoint, early])\n",
        "    \n",
        "    return hist\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "hist = run()\n",
        "Execution output\n",
        "5KB\n",
        "\tStream\n",
        "\t\t(17500, 2)\n",
        "\t\tFound 17500 validated image filenames belonging to 2 classes.\n",
        "\t\tFound 7500 validated image filenames belonging to 2 classes.\n",
        "\t\tModel: \"sequential_10\"\n",
        "\t\t_________________________________________________________________\n",
        "\t\t Layer (type)                Output Shape              Param #   \n",
        "\t\t=================================================================\n",
        "\t\t conv2d_130 (Conv2D)         (None, 64, 64, 64)        1792      \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_131 (Conv2D)         (None, 64, 64, 64)        36928     \n",
        "\t\t                                                                 \n",
        "\t\t max_pooling2d_50 (MaxPoolin  (None, 32, 32, 64)       0         \n",
        "\t\t g2D)                                                            \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_132 (Conv2D)         (None, 32, 32, 128)       73856     \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_133 (Conv2D)         (None, 32, 32, 128)       147584    \n",
        "\t\t                                                                 \n",
        "\t\t max_pooling2d_51 (MaxPoolin  (None, 16, 16, 128)      0         \n",
        "\t\t g2D)                                                            \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_134 (Conv2D)         (None, 16, 16, 256)       295168    \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_135 (Conv2D)         (None, 16, 16, 256)       590080    \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_136 (Conv2D)         (None, 16, 16, 256)       590080    \n",
        "\t\t                                                                 \n",
        "\t\t max_pooling2d_52 (MaxPoolin  (None, 8, 8, 256)        0         \n",
        "\t\t g2D)                                                            \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_137 (Conv2D)         (None, 8, 8, 512)         1180160   \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_138 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_139 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
        "\t\t                                                                 \n",
        "\t\t max_pooling2d_53 (MaxPoolin  (None, 4, 4, 512)        0         \n",
        "\t\t g2D)                                                            \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_140 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_141 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
        "\t\t                                                                 \n",
        "\t\t conv2d_142 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
        "\t\t                                                                 \n",
        "\t\t max_pooling2d_54 (MaxPoolin  (None, 2, 2, 512)        0         \n",
        "\t\t g2D)                                                            \n",
        "\t\t                                                                 \n",
        "\t\t flatten_10 (Flatten)        (None, 2048)              0         \n",
        "\t\t                                                                 \n",
        "\t\t dense_30 (Dense)            (None, 4096)              8392704   \n",
        "\t\t                                                                 \n",
        "\t\t dense_31 (Dense)            (None, 4096)              16781312  \n",
        "\t\t                                                                 \n",
        "\t\t dense_32 (Dense)            (None, 2)                 8194      \n",
        "\t\t                                                                 \n",
        "\t\t=================================================================\n",
        "\t\tTotal params: 39,896,898\n",
        "\t\tTrainable params: 39,896,898\n",
        "\t\tNon-trainable params: 0\n",
        "\t\t_________________________________________________________________\n",
        "\t\t/Users/ivastival/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
        "\t\tWARNING:tensorflow:6 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7f913ee94510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "\t\t\n",
        "\t\tEpoch 00001: accuracy improved from -inf to 0.42969, saving model to /Users/ivastival/OneDrive/Developer/DataScience/TranferLearning//models/vgg16_1.h5\n",
        "\t\t1/1 [==============================] - 73s 73s/step - loss: 0.6933 - accuracy: 0.4297 - val_loss: 0.7010 - val_accuracy: 0.5109\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "for key in hist.history:\n",
        "    print(key)\n",
        "Execution output\n",
        "0KB\n",
        "\tStream\n",
        "\t\tloss\n",
        "\t\taccuracy\n",
        "\t\tval_loss\n",
        "\t\tval_accuracy\n",
        "\n",
        "Code cell <undefined>\n",
        "#%% [code]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQtB3l8VP7-P"
      },
      "id": "jQtB3l8VP7-P",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "vgg16_notebook.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}