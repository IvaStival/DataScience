{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras, os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "jQtB3l8VP7-P"
      },
      "id": "jQtB3l8VP7-P",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.getcwd().split(\"code\")[0]\n",
        "dataset_name = \"dogs-vs-cats\"\n",
        "unzip = False\n",
        "\n",
        "def unzipDataSet(zipfile_name, directory):\n",
        "    with zipfile.ZipFile(f\"{path}/dataset/{dataset_name}/{zipfile_name}\", \"r\") as z:\n",
        "        z.extractall(f\"{path}/dataset/images/{directory}\")\n",
        "\n",
        "def createDataFrameFromDirectory(directory):\n",
        "    list_of_files = [os.path.join(f\"{path}/dataset/images/{directory}\", file) for file in os.listdir(f\"{path}/dataset/images/{directory}\")]\n",
        "\n",
        "    df = pd.DataFrame({\"Path\" : list_of_files})\n",
        "    df[\"animal\"] = np.where(df[\"Path\"].str.contains(\"dog\"), \"dog\", \"cat\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "RY-XrNukH09M"
      },
      "id": "RY-XrNukH09M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(input_shape = (64,64, 3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "W5pNAOgaH713"
      },
      "id": "W5pNAOgaH713",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    if unzip:\n",
        "        unzipDataSet(\"train.zip\", \"train\")\n",
        "        unzipDataSet(\"test1.zip\", \"test\")\n",
        "\n",
        "    df_train = createDataFrameFromDirectory(\"train/train\")\n",
        "    df_test = createDataFrameFromDirectory(\"test/test1\")\n",
        "\n",
        "    X_Train, X_Test = train_test_split(df_train, test_size=0.3)\n",
        "\n",
        "    print(X_Train.shape)\n",
        "\n",
        "    tr_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                    shear_range = 0.2,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "    ts_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "    train_set = tr_datagen.flow_from_dataframe(dataframe=X_Train, x_col=\"Path\", y_col=\"animal\", class_mode=\"categorical\", target_size=(64,64), batch_size=128)\n",
        "    test_set  = ts_datagen.flow_from_dataframe(dataframe=X_Test,  x_col=\"Path\", y_col=\"animal\", class_mode=\"categorical\", target_size=(64,64), batch_size=128)\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model = setModel()\n",
        "\n",
        "    model.compile(optimizer = opt, loss=categorical_crossentropy, metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    checkpoint = ModelCheckpoint(f\"{path}/models/vgg16_1.h5\", monitor=\"accuracy\", verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", save_freq=1)\n",
        "    early = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=20, verbose=1, mode=\"auto\")\n",
        "\n",
        "    hist = model.fit_generator(steps_per_epoch=1, generator=train_set, validation_data=test_set, validation_steps=10, epochs=1, callbacks=[checkpoint, early])\n",
        "    \n",
        "    return hist"
      ],
      "metadata": {
        "id": "7HOh3cFQH959"
      },
      "id": "7HOh3cFQH959",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "vgg16_notebook.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}