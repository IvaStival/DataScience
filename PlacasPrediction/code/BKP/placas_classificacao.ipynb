{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "from skimage import io, transform, exposure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSVs Tran and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train = pd.read_csv(\"../dataset/archive/Train.csv\")[[\"ClassId\", \"Path\"]]\n",
    "df_Test = pd.read_csv(\"../dataset/archive/Test.csv\")[[\"ClassId\", \"Path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39204</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00025.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39205</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00026.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39206</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39207</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00028.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39208</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00029.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39209 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ClassId                            Path\n",
       "0           20  Train/20/00020_00000_00000.png\n",
       "1           20  Train/20/00020_00000_00001.png\n",
       "2           20  Train/20/00020_00000_00002.png\n",
       "3           20  Train/20/00020_00000_00003.png\n",
       "4           20  Train/20/00020_00000_00004.png\n",
       "...        ...                             ...\n",
       "39204       42  Train/42/00042_00007_00025.png\n",
       "39205       42  Train/42/00042_00007_00026.png\n",
       "39206       42  Train/42/00042_00007_00027.png\n",
       "39207       42  Train/42/00042_00007_00028.png\n",
       "39208       42  Train/42/00042_00007_00029.png\n",
       "\n",
       "[39209 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 39209 images (75.63610409151411)\n",
      "Test Size: 12630 images (24.363895908485887)\n"
     ]
    }
   ],
   "source": [
    "total = df_Train.shape[0]+df_Test.shape[0]\n",
    "print(f\"Train Size: {df_Train.shape[0]} images ({df_Train.shape[0]/ total*100})\")\n",
    "print(f\"Test Size: {df_Test.shape[0]} images ({df_Test.shape[0]/ total*100})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Load Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function first shuffle the dataset, after load the image to memory, resize it, equelize the contrast and finally save to an array.\n",
    "def load_images(main_path, df):\n",
    "    data = []\n",
    "    \n",
    "    # SHUFFLE DATA FRAME\n",
    "    df_shuffle = df.sample(frac=1)\n",
    "    \n",
    "    for (i, image_path) in enumerate(df):\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(f\"[DEBUG] Total processed images: {i}\")\n",
    "            \n",
    "        image_full_path = os.path.sep.join([main_path, image_path])\n",
    "        image = io.imread(image_full_path)\n",
    "\n",
    "        image = transform.resize(image, (32,32))\n",
    "        image = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
    "\n",
    "        data.append(image)\n",
    "            \n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "\n",
    "        inputShape = (height, width, depth)\n",
    "        dim = 1\n",
    "\n",
    "        model.add(Conv2D(8, (5,5), padding = \"same\", input_shape = inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=dim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(16, (3,3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=dim))\n",
    "        model.add(Conv2D(16, (3,3), padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=dim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=dim))\n",
    "        model.add(Conv2D(32, (3,3), padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=dim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    NUM_EPOCHS = 30\n",
    "    INIT_LR = 0.001\n",
    "    BS = 64\n",
    "    \n",
    "    print(f\"[DEBUG] Loading dataset ...\\n\")\n",
    "    df_Train = pd.read_csv(\"../dataset/archive/Train.csv\")[[\"ClassId\", \"Path\"]]\n",
    "    df_Test = pd.read_csv(\"../dataset/archive/Test.csv\")[[\"ClassId\", \"Path\"]]\n",
    "    label_names = pd.read_csv(\"../dataset/archive/signnames.csv\")[\"SignName\"]\n",
    "    \n",
    "    print(f\"[DEBUG] Load images from file and prepare data ...\\n\")\n",
    "    X_Train = load_images(\"../dataset/archive\", df_Train[\"Path\"])\n",
    "    X_Test = load_images(\"../dataset/archive\", df_Test[\"Path\"])\n",
    "\n",
    "    # GET THE TOTAL UNIQUE TRANSIT SIGN\n",
    "    num_labels = df_Train[\"ClassId\"].unique().size\n",
    "    \n",
    "    # GET THE Y CLASS\n",
    "    Y_Train = np.array(df_Train[\"ClassId\"])\n",
    "    Y_Test = np.array(df_Test[\"ClassId\"])\n",
    "    \n",
    "    # NORMALIZE THE RGB PIXELS VALUES\n",
    "    X_Train = X_Train.astype(\"float32\") / 255.0\n",
    "    X_Test  = X_Test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    # ONE HOT ENCODING\n",
    "    Y_Train = to_categorical(Y_Train, num_labels)\n",
    "    Y_Test = to_categorical(Y_Test, num_labels)  \n",
    "    \n",
    "    # CREATE A DICTIONARY BY CLASS AND CALC THE WEIGHT, THIS BECAUSE THE DATASET IS NOT HOMOGENEOUS\n",
    "    # GET THE TOTAL TRANSIT SIGN IMAGES\n",
    "    total_classes = Y_Train.sum(axis=0)\n",
    "    class_weight = dict()\n",
    "    \n",
    "    # CALCULATE THE CLASS WEIGHT\n",
    "    for i in range(0, len(total_classes)):\n",
    "        class_weight[i] = total_classes.max() / total_classes[i]\n",
    "        \n",
    "    # IMAGE GENERATOR\n",
    "    img_gen = ImageDataGenerator(rotation_range = 10,\n",
    "                                 zoom_range = 0.15,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 shear_range = 0.15,\n",
    "                                 horizontal_flip = False,\n",
    "                                 vertical_flip = False,\n",
    "                                 fill_mode = \"nearest\")\n",
    "    \n",
    "    print(f\"[DEBUG] Config Model ...\\n\")\n",
    "    # ADAM OPTIMIZER\n",
    "    opt = Adam(learning_rate=INIT_LR, decay = INIT_LR / (NUM_EPOCHS * 0.5))\n",
    "    \n",
    "    # CNN\n",
    "    model = build(width = 32, height = 32, depth = 3, classes = num_labels)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    \n",
    "    print(f\"[DEBUG] Training ...\\n\")\n",
    "    \n",
    "    hist = model.fit(img_gen.flow(X_Train, Y_Train, batch_size = BS),\n",
    "                    validation_data = (X_Test, Y_Test), \n",
    "                    steps_per_epoch = X_Train.shape[0] // BS,\n",
    "                    epochs = NUM_EPOCHS,\n",
    "                    class_weight = class_weight,\n",
    "                    verbose = 1)\n",
    "    \n",
    "    print(f\"[DEBUG] Evaluating ...\\n\")\n",
    "    prediction = model.predict(X_Test, batch_size = BS)\n",
    "    print(classification_report(Y_Test.argmax(axis=1), prediction.argmax(axis=1), target_names = label_names))\n",
    "    \n",
    "    # GETTING THE CURRENT TIME\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    # SAVING MODEL\n",
    "    model_path = \"../models/sign_model_\" + date\n",
    "    print(f\"[INFO] serialiazing network to {model_path}\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading dataset ...\n",
      "\n",
      "[DEBUG] Load images from file and prepare data ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivastival/opt/anaconda3/lib/python3.7/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Total processed images: 1000\n",
      "[DEBUG] Total processed images: 2000\n",
      "[DEBUG] Total processed images: 3000\n",
      "[DEBUG] Total processed images: 4000\n",
      "[DEBUG] Total processed images: 5000\n",
      "[DEBUG] Total processed images: 6000\n",
      "[DEBUG] Total processed images: 7000\n",
      "[DEBUG] Total processed images: 8000\n",
      "[DEBUG] Total processed images: 9000\n",
      "[DEBUG] Total processed images: 10000\n",
      "[DEBUG] Total processed images: 11000\n",
      "[DEBUG] Total processed images: 12000\n",
      "[DEBUG] Total processed images: 13000\n",
      "[DEBUG] Total processed images: 14000\n",
      "[DEBUG] Total processed images: 15000\n",
      "[DEBUG] Total processed images: 16000\n",
      "[DEBUG] Total processed images: 17000\n",
      "[DEBUG] Total processed images: 18000\n",
      "[DEBUG] Total processed images: 19000\n",
      "[DEBUG] Total processed images: 20000\n",
      "[DEBUG] Total processed images: 21000\n",
      "[DEBUG] Total processed images: 22000\n",
      "[DEBUG] Total processed images: 23000\n",
      "[DEBUG] Total processed images: 24000\n",
      "[DEBUG] Total processed images: 25000\n",
      "[DEBUG] Total processed images: 26000\n",
      "[DEBUG] Total processed images: 27000\n",
      "[DEBUG] Total processed images: 28000\n",
      "[DEBUG] Total processed images: 29000\n",
      "[DEBUG] Total processed images: 30000\n",
      "[DEBUG] Total processed images: 31000\n",
      "[DEBUG] Total processed images: 32000\n",
      "[DEBUG] Total processed images: 33000\n",
      "[DEBUG] Total processed images: 34000\n",
      "[DEBUG] Total processed images: 35000\n",
      "[DEBUG] Total processed images: 36000\n",
      "[DEBUG] Total processed images: 37000\n",
      "[DEBUG] Total processed images: 38000\n",
      "[DEBUG] Total processed images: 39000\n",
      "[DEBUG] Total processed images: 1000\n",
      "[DEBUG] Total processed images: 2000\n",
      "[DEBUG] Total processed images: 3000\n",
      "[DEBUG] Total processed images: 4000\n",
      "[DEBUG] Total processed images: 5000\n",
      "[DEBUG] Total processed images: 6000\n",
      "[DEBUG] Total processed images: 7000\n",
      "[DEBUG] Total processed images: 8000\n",
      "[DEBUG] Total processed images: 9000\n",
      "[DEBUG] Total processed images: 10000\n",
      "[DEBUG] Total processed images: 11000\n",
      "[DEBUG] Total processed images: 12000\n",
      "[DEBUG] Config Model ...\n",
      "\n",
      "[DEBUG] Training ...\n",
      "\n",
      "Epoch 1/30\n",
      "612/612 [==============================] - 55s 88ms/step - loss: 8.8225 - accuracy: 0.1020 - val_loss: 9.2853 - val_accuracy: 0.0903\n",
      "Epoch 2/30\n",
      "612/612 [==============================] - 53s 87ms/step - loss: 5.7427 - accuracy: 0.2903 - val_loss: 20.0388 - val_accuracy: 0.0280\n",
      "Epoch 3/30\n",
      "612/612 [==============================] - 53s 87ms/step - loss: 4.6984 - accuracy: 0.4043 - val_loss: 7.4477 - val_accuracy: 0.0852\n",
      "Epoch 4/30\n",
      "612/612 [==============================] - 54s 88ms/step - loss: 4.0104 - accuracy: 0.4764 - val_loss: 1.9667 - val_accuracy: 0.3904\n",
      "Epoch 5/30\n",
      "612/612 [==============================] - 63s 103ms/step - loss: 3.5721 - accuracy: 0.5248 - val_loss: 3.3295 - val_accuracy: 0.3062\n",
      "Epoch 6/30\n",
      "612/612 [==============================] - 68s 110ms/step - loss: 3.2613 - accuracy: 0.5575 - val_loss: 0.9110 - val_accuracy: 0.6874\n",
      "Epoch 7/30\n",
      "612/612 [==============================] - 65s 106ms/step - loss: 2.9691 - accuracy: 0.5878 - val_loss: 1.7419 - val_accuracy: 0.4512\n",
      "Epoch 8/30\n",
      "612/612 [==============================] - 67s 110ms/step - loss: 2.8117 - accuracy: 0.6058 - val_loss: 1.3049 - val_accuracy: 0.5812\n",
      "Epoch 9/30\n",
      "612/612 [==============================] - 66s 107ms/step - loss: 2.6075 - accuracy: 0.6293 - val_loss: 1.5000 - val_accuracy: 0.5668\n",
      "Epoch 10/30\n",
      "612/612 [==============================] - 64s 104ms/step - loss: 2.4918 - accuracy: 0.6485 - val_loss: 2.8904 - val_accuracy: 0.3625\n",
      "Epoch 11/30\n",
      "612/612 [==============================] - 71s 116ms/step - loss: 2.2379 - accuracy: 0.6711 - val_loss: 0.8194 - val_accuracy: 0.7297\n",
      "Epoch 12/30\n",
      "612/612 [==============================] - 77s 126ms/step - loss: 2.1555 - accuracy: 0.6865 - val_loss: 0.5679 - val_accuracy: 0.8230\n",
      "Epoch 13/30\n",
      "612/612 [==============================] - 70s 114ms/step - loss: 2.0560 - accuracy: 0.7051 - val_loss: 0.8413 - val_accuracy: 0.7264\n",
      "Epoch 14/30\n",
      "612/612 [==============================] - 75s 123ms/step - loss: 1.9544 - accuracy: 0.7139 - val_loss: 0.7112 - val_accuracy: 0.7793\n",
      "Epoch 15/30\n",
      "612/612 [==============================] - 78s 127ms/step - loss: 1.8110 - accuracy: 0.7303 - val_loss: 0.6512 - val_accuracy: 0.7716\n",
      "Epoch 16/30\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 1.7362 - accuracy: 0.7384 - val_loss: 0.5605 - val_accuracy: 0.8242\n",
      "Epoch 17/30\n",
      "612/612 [==============================] - 67s 109ms/step - loss: 1.6327 - accuracy: 0.7523 - val_loss: 0.6352 - val_accuracy: 0.7918\n",
      "Epoch 18/30\n",
      "612/612 [==============================] - 77s 126ms/step - loss: 1.5579 - accuracy: 0.7695 - val_loss: 0.5639 - val_accuracy: 0.8179\n",
      "Epoch 19/30\n",
      "612/612 [==============================] - 71s 117ms/step - loss: 1.5230 - accuracy: 0.7748 - val_loss: 0.5448 - val_accuracy: 0.8262\n",
      "Epoch 20/30\n",
      "612/612 [==============================] - 67s 110ms/step - loss: 1.4421 - accuracy: 0.7828 - val_loss: 0.4883 - val_accuracy: 0.8566\n",
      "Epoch 21/30\n",
      "612/612 [==============================] - 67s 110ms/step - loss: 1.3969 - accuracy: 0.7907 - val_loss: 0.4785 - val_accuracy: 0.8600\n",
      "Epoch 22/30\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 1.3301 - accuracy: 0.7990 - val_loss: 0.4129 - val_accuracy: 0.8781\n",
      "Epoch 23/30\n",
      "612/612 [==============================] - 77s 125ms/step - loss: 1.2653 - accuracy: 0.8091 - val_loss: 0.3773 - val_accuracy: 0.8924\n",
      "Epoch 24/30\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 1.2476 - accuracy: 0.8102 - val_loss: 0.4384 - val_accuracy: 0.8617\n",
      "Epoch 25/30\n",
      "612/612 [==============================] - 80s 130ms/step - loss: 1.1943 - accuracy: 0.8182 - val_loss: 0.3820 - val_accuracy: 0.8854\n",
      "Epoch 26/30\n",
      "612/612 [==============================] - 79s 129ms/step - loss: 1.1625 - accuracy: 0.8231 - val_loss: 0.4330 - val_accuracy: 0.8746\n",
      "Epoch 27/30\n",
      "612/612 [==============================] - 74s 121ms/step - loss: 1.1140 - accuracy: 0.8314 - val_loss: 0.4703 - val_accuracy: 0.8683\n",
      "Epoch 28/30\n",
      "612/612 [==============================] - 73s 119ms/step - loss: 1.0980 - accuracy: 0.8319 - val_loss: 0.3839 - val_accuracy: 0.8840\n",
      "Epoch 29/30\n",
      "612/612 [==============================] - 82s 135ms/step - loss: 1.0551 - accuracy: 0.8391 - val_loss: 0.3645 - val_accuracy: 0.8931\n",
      "Epoch 30/30\n",
      "612/612 [==============================] - 81s 132ms/step - loss: 1.0269 - accuracy: 0.8454 - val_loss: 0.4548 - val_accuracy: 0.8532\n",
      "[DEBUG] Evaluating ...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-3a8c0635d9b2>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[DEBUG] Evaluating ...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# GETTING THE CURRENT TIME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_names' is not defined"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  Speed limit (20km/h)\n",
       "1                                  Speed limit (30km/h)\n",
       "2                                  Speed limit (50km/h)\n",
       "3                                  Speed limit (60km/h)\n",
       "4                                  Speed limit (70km/h)\n",
       "5                                  Speed limit (80km/h)\n",
       "6                           End of speed limit (80km/h)\n",
       "7                                 Speed limit (100km/h)\n",
       "8                                 Speed limit (120km/h)\n",
       "9                                            No passing\n",
       "10         No passing for vechiles over 3.5 metric tons\n",
       "11                Right-of-way at the next intersection\n",
       "12                                        Priority road\n",
       "13                                                Yield\n",
       "14                                                 Stop\n",
       "15                                          No vechiles\n",
       "16             Vechiles over 3.5 metric tons prohibited\n",
       "17                                             No entry\n",
       "18                                      General caution\n",
       "19                          Dangerous curve to the left\n",
       "20                         Dangerous curve to the right\n",
       "21                                         Double curve\n",
       "22                                           Bumpy road\n",
       "23                                        Slippery road\n",
       "24                            Road narrows on the right\n",
       "25                                            Road work\n",
       "26                                      Traffic signals\n",
       "27                                          Pedestrians\n",
       "28                                    Children crossing\n",
       "29                                    Bicycles crossing\n",
       "30                                   Beware of ice/snow\n",
       "31                                Wild animals crossing\n",
       "32                  End of all speed and passing limits\n",
       "33                                     Turn right ahead\n",
       "34                                      Turn left ahead\n",
       "35                                           Ahead only\n",
       "36                                 Go straight or right\n",
       "37                                  Go straight or left\n",
       "38                                           Keep right\n",
       "39                                            Keep left\n",
       "40                                 Roundabout mandatory\n",
       "41                                    End of no passing\n",
       "42    End of no passing by vechiles over 3.5 metric ...\n",
       "Name: SignName, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
